{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soledad-escobar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfData = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/events_up_to_01062018.csv')\n",
    "dfTrain = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/labels_training_set.csv')\n",
    "dfTest = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/trocafone_kaggle_test.csv')\n",
    "dfSample = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/trocafone_kaggle_submit_sample_all_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Crea un df con todos los usuarios\n",
    "dfTest['label'] = 0\n",
    "dfUsers = pd.concat([dfTrain,dfTest])\n",
    "dfTest = dfTest.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soledad-escobar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Le asigna a cada usuario su cantidad de eventos dandole mas valor si son mas recientes\n",
    "def pesoTiempo(time):\n",
    "    mes = int(time[6])\n",
    "    dia = int(time[8:10])\n",
    "    if mes < 5:\n",
    "        return 1\n",
    "    return 10 + dia * 0.7\n",
    "    \n",
    "dfPE = dfData[['person', 'event', 'timestamp']]\n",
    "dfPE['puntajeTiempo'] = dfPE['timestamp'].apply(pesoTiempo)\n",
    "dfPE = pd.get_dummies(dfPE, columns=['event'])\n",
    "columnasEventos = dfPE.columns.values[3:]\n",
    "for eventoColumna in columnasEventos:\n",
    "    dfPE[eventoColumna] *= dfPE['puntajeTiempo']\n",
    "dfPE = dfPE.drop(['timestamp', 'puntajeTiempo'], axis=1).groupby('person').sum()\n",
    "dfUsers = dfUsers.sort_values('person').merge(dfPE, on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soledad-escobar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Le asigna a cada usuario la region en la que mas eventos tiene\n",
    "regionesMasEventos = dfData['region'].value_counts().head(9).index.tolist()\n",
    "def filtrarRegiones(region):\n",
    "    if pd.isnull(region):\n",
    "        return 'null'\n",
    "    if region not in regionesMasEventos:\n",
    "        return 'Other'\n",
    "    return region\n",
    "    \n",
    "dfPE = dfData[['person', 'region']]\n",
    "dfPE['regionAcotada'] = dfPE['region'].apply(filtrarRegiones)\n",
    "\n",
    "lDictRegiones = []\n",
    "temp = dfPE.drop('region', axis=1).groupby('person')\n",
    "for name, group in temp:\n",
    "    regiones = {'null' : 1}\n",
    "    for row in group.itertuples():\n",
    "        region = row.regionAcotada\n",
    "        if region == 'null':\n",
    "            continue\n",
    "        if region in regiones:\n",
    "            regiones[region] += 1\n",
    "        else:\n",
    "            regiones[region] = 1\n",
    "        rMax = max(regiones, key=regiones.get)\n",
    "    lDictRegiones.append({'person' : name, 'region' : rMax})\n",
    "\n",
    "dfRegiones = pd.DataFrame(lDictRegiones)\n",
    "dfRegiones = pd.get_dummies(dfRegiones, columns=['region'])\n",
    "dfUsers = dfUsers.merge(dfRegiones, on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casteo dfUsers a int32\n",
    "personas = dfUsers['person']\n",
    "dfUsers.drop('person', axis=1, inplace=True)\n",
    "dfUsers = dfUsers.astype('int32')\n",
    "dfUsers['person'] = personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columna con ultima visita al sitio\n",
    "temp = dfData.groupby('person')['timestamp'].max().to_frame()\n",
    "dfUsers = dfUsers.merge(temp, on='person')\n",
    "dfUsers['month'] = dfUsers['timestamp'].str[5:7]\n",
    "dfUsers['day'] = dfUsers['timestamp'].str[8:10]\n",
    "dfUsers[['day','month']] = dfUsers[['day','month']].apply(pd.to_numeric)\n",
    "dfUsers['last_visit'] = dfUsers['month']*30 + dfUsers['day']\n",
    "dfUsers = dfUsers.drop(['timestamp','month','day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columna con ultima compra\n",
    "temp = dfData.loc[dfData['event'].isin(['conversion','lead','checkout'])]\\\n",
    "             .groupby('person')['timestamp'].max().to_frame()\n",
    "dfUsers = dfUsers.merge(temp, how='left', on='person')\n",
    "dfUsers = dfUsers.fillna('000000000000000000')\n",
    "dfUsers['month'] = dfUsers['timestamp'].str[5:7]\n",
    "dfUsers['day'] = dfUsers['timestamp'].str[8:10]\n",
    "dfUsers[['day','month']] = dfUsers[['day','month']].apply(pd.to_numeric)\n",
    "dfUsers['last_conversion'] = dfUsers['month']*30 + dfUsers['day']\n",
    "dfUsers = dfUsers.drop(['timestamp','month','day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soledad-escobar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Columna con relacion entre el uso del celular y de la computadora\n",
    "def filtrarDispositivo(deviceType):\n",
    "    if deviceType == 'Computer':\n",
    "        return 1\n",
    "    elif deviceType == 'Smartphone':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "dfPE = dfData[['person', 'device_type']]\n",
    "dfPE['dispositivo'] = dfPE['device_type'].apply(filtrarDispositivo)\n",
    "dfPE = dfPE.loc[dfPE['dispositivo'] != 2].drop('device_type', axis=1).groupby('person').mean()\n",
    "dfUsers = dfUsers.merge(dfPE, on='person', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757998577849335"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_y = dfTrain['label']\n",
    "df_X = dfTrain.drop('label', axis=1).merge(dfUsers, on='person').drop(['person','label'], axis=1)\n",
    "\n",
    "GBC = GradientBoostingClassifier(random_state=23)\n",
    "scores = cross_val_score(GBC , df_X, df_y, scoring=\"roc_auc\", cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762803326776337"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruebo con XGBoost\n",
    "XGBC = xgb.XGBClassifier(learning_rate =0.075, n_estimators=95, max_depth=4, min_child_weight=6, \n",
    "                         gamma=0.3, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',\n",
    "                         scale_pos_weight=0.8, seed = 15)\n",
    "\n",
    "scores = cross_val_score(XGBC , df_X, df_y, scoring=\"roc_auc\", cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773219873778414"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "VC = VotingClassifier(estimators=[('xgb', XGBC), ('gb', GBC)], voting='soft', weights = [1.8,0.9])\n",
    "scores = cross_val_score(VC , df_X, df_y, scoring=\"roc_auc\", cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrego nuevos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego columnas para separar los meses y la hora\n",
    "datos = dfData.loc[:,['timestamp', 'event', 'person']]\n",
    "datos['date_time'] = pd.to_datetime(datos['timestamp'], format='%Y%m%d %H:%M:%S.%f')\n",
    "datos['mes'] = datos['date_time'].dt.month\n",
    "datos['hora'] = datos['date_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columnas para ver el momento del dia en el que se generaron las conversiones\n",
    "features = datos.loc[ datos['event'] == 'conversion', ['person', 'hora']]\n",
    "features['mañana'] = features['hora'].apply(lambda x: 1 if ((x >= 6) & (x < 12)) else 0)\n",
    "features['tarde'] = features['hora'].apply(lambda x: 1 if ((x >= 12) & (x <20)) else 0)\n",
    "features['noche'] = features['hora'].apply(lambda x: 1 if ((x >= 20) & (x <= 23)) else 0)\n",
    "features['madrugada'] = features['hora'].apply(lambda x: 1 if ((x >= 0) & (x < 6)) else 0)\n",
    "features = features.drop('hora', axis = 'columns').groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago un join con los features anteriores\n",
    "df_feat = pd.merge(dfUsers, features, on = 'person', how = 'left').fillna(0.0).drop('label', axis = 'columns')\n",
    "# Agrego la cantidad de eventos que generaron las personas\n",
    "df_feat['total_events'] = (np.sum(df_feat.filter(items = ['event_ad campaign hit','event_brand listing', 'event_checkout', \n",
    "                                                         'event_conversion', 'event_generic listing', 'event_lead', 'event_search engine hit', \n",
    "                                                         'event_searched products', 'event_staticpage', 'event_viewed product','event_visited site']), \n",
    "    axis = 'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Me quedo solo con los datos de las pñersonas que tienen labels\n",
    "df_features = df_feat.merge(dfTrain, on = 'person')\n",
    "\n",
    "y = df_features['label']\n",
    "X = df_features.drop(['person', 'label'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizo las predicciones y luego calculo el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0061182 , 0.00419453, 0.02128958, ..., 0.02706209, 0.26649815,\n",
       "       0.0039666 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBC.fit(X_train, y_train)\n",
    "preds = XGBC.predict_proba(X_test)[:,1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723067685424042"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGBC , X, y, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el score bajó veo como mejorar mis features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mañana': 463.0, 'tarde': 3400.0, 'noche': 1755.0, 'madrugada': 1473.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo en que momento del día se realizan más compras\n",
    "ranking = {'mañana': df_feat['mañana'].sum(), 'tarde': df_feat['tarde'].sum(), 'noche': df_feat['noche'].sum(), 'madrugada': df_feat['madrugada'].sum()}\n",
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego una columna para calcular la cantidad de conversiones realizadas sobre el total de eventos relaizados\n",
    "df_feat['posible_conversion'] = (df_feat['event_conversion']/ df_features['total_events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719796203099616"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me quedo solo con las personas que tienen labels\n",
    "df_features_1 = df_feat.merge(dfTrain, on = 'person')\n",
    "\n",
    "y1 = df_features_1['label']\n",
    "X1 = df_features_1.drop(['person', 'label'], axis=1)\n",
    "\n",
    "scores = cross_val_score(XGBC , X1, y1, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el ranking realizado se ve en que momentos del día se realizan más conversiones, creo columnas para asignar más peso a las conversiones \"más posibles\" segun el momento del dia en el que ingresa el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat['posib_conv_mañ'] = (df_feat['posible_conversion'] + df_feat['mañana'])\n",
    "df_feat['posib_conv_tar'] =(df_feat['posible_conversion'] + df_feat['tarde'])\n",
    "df_feat['posib_conv_noch'] = (df_feat['posible_conversion'] + df_feat['noche'])\n",
    "df_feat['posib_conv_mad'] = (df_feat['posible_conversion']+ df_feat['madrugada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872438622363557"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me quedo solo con las personas que tienen labels\n",
    "df_features_2 = df_feat.merge(dfTrain, on = 'person')\n",
    "\n",
    "y2 = df_features_2['label']\n",
    "X2 = df_features_2.drop(['person', 'label'], axis=1)\n",
    "\n",
    "scores = cross_val_score(XGBC , X2, y2, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los nuevos features solo bajan aun más la precisión del algoritmo, los descarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego la relación entre checkouts y conversiones\n",
    "df_feat['conversion/checkout'] = (df_feat['event_conversion'] / df_feat['event_checkout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarto los features anteriores\n",
    "new_df_features = df_feat.drop(['posib_conv_mañ', 'posib_conv_tar', 'posib_conv_noch','posib_conv_mad'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740131350505322"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me quedo solo con las personas que tienen labels\n",
    "df_features_3 = new_df_features.merge(dfTrain, on = 'person')\n",
    "\n",
    "y3 = df_features_3['label']\n",
    "X3 = df_features_3.drop(['person', 'label'], axis=1)\n",
    "\n",
    "scores = cross_val_score(XGBC , X3, y3, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego más features sobre marcas y modelos de los productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se tienen muchos modelos diferentes pero corresponden a una cantidad acotada de marcas, trabajo sobre las marcas para crear nuevos features. Creo una columna por cada marca existente y para cada persona coloco el promedio de compra para esa marca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas = dfData.loc[:, ['model', 'person']]\n",
    "marcas['Samsung'] = marcas['model'].apply(lambda x: 1 if ('samsung' in str(x).lower()) else 0)\n",
    "marcas['iPhone'] = marcas['model'].apply(lambda x: 1 if ('iphone' in str(x).lower()) else 0)\n",
    "marcas['Motorola'] = marcas['model'].apply(lambda x: 1 if ('moto' in str(x).lower()) else 0)\n",
    "marcas['Lenovo'] = marcas['model'].apply(lambda x: 1 if ('lenovo' in str(x).lower()) else 0)\n",
    "marcas['LG'] = marcas['model'].apply(lambda x: 1 if ('lg' in str(x).lower()) else 0)\n",
    "marcas['Sony'] = marcas['model'].apply(lambda x: 1 if ('sony' in str(x).lower()) else 0)\n",
    "marcas['Asus'] = marcas['model'].apply(lambda x: 1 if ('asus' in str(x).lower()) else 0)\n",
    "marcas['iPad'] = marcas['model'].apply(lambda x: 1 if ('ipad' in str(x).lower()) else 0)\n",
    "marcas['Quantum'] = marcas['model'].apply(lambda x: 1 if ('quantum' in str(x).lower()) else 0)\n",
    "dfFeat = marcas.groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago join con los features anteriores \n",
    "new_features = pd.merge(new_df_features, dfFeat, on = 'person', how = 'left').fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vuelvo a correr XGBoost para ver si con los nuevos features mejoran las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con las personas que tienen labels\n",
    "df_features_4 = new_features.merge(dfTrain, on = 'person')\n",
    "\n",
    "y4 = df_features_4['label']\n",
    "X4 = df_features_4.drop(['person', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8750625603092634"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGBC , X4, y4, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo nuevos features para posibilidad de compra según la marca que visite el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo columnas para las marcas existentes\n",
    "compras_por_marcas = dfData.loc[dfData['event'] == 'conversion', ['model', 'person']]\n",
    "compras_por_marcas['Samsung_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('samsung' in x.lower()) else 0)\n",
    "compras_por_marcas['iPhone_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('iphone' in x.lower()) else 0)\n",
    "compras_por_marcas['Motorola_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('moto' in x.lower()) else 0)\n",
    "compras_por_marcas['Lenovo_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('lenovo' in x.lower()) else 0)\n",
    "compras_por_marcas['LG_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('lg' in x.lower()) else 0)\n",
    "compras_por_marcas['Sony_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('sony' in x.lower()) else 0)\n",
    "compras_por_marcas['Asus_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('asus' in x.lower()) else 0)\n",
    "compras_por_marcas['iPad_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('iPad' in x.lower()) else 0)\n",
    "compras_por_marcas['Quantum_comp'] = compras_por_marcas['model'].apply(lambda x: 1 if ('quantum' in x.lower()) else 0)\n",
    "features = compras_por_marcas.groupby('person').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_features = pd.merge(new_features, features, on = 'person', how = 'left').fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con las personas que tienen labels\n",
    "df_features_5 = set_features.merge(dfTrain, on = 'person')\n",
    "\n",
    "y5 = df_features_5['label']\n",
    "X5 = df_features_5.drop(['person', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8748216507702689"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGBC, X5, y5, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
