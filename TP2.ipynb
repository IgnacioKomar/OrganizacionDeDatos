{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soledad-escobar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfE = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/events_up_to_01062018.csv')\n",
    "dfT = pd.read_csv('/home/soledad-escobar/Descargas/Orga_datos/fiuba-trocafone-tp2-final-set/labels_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE a columna event\n",
    "dfD = dfE[['person', 'event']]\n",
    "dfD = pd.get_dummies(dfD, columns=['event']).groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le agrego las features de event a las labels\n",
    "dfTD = dfT.sort_values('person').merge(dfD, on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columna con ultima visita al sitio\n",
    "temp = dfE.groupby('person')['timestamp'].max().to_frame()\n",
    "dfTDb = dfTD.merge(temp, on='person')\n",
    "dfTDb['month'] = dfTDb['timestamp'].str[5:7]\n",
    "dfTDb['day'] = dfTDb['timestamp'].str[8:10]\n",
    "dfTDb[['day','month']] = dfTDb[['day','month']].apply(pd.to_numeric)\n",
    "dfTDb['last_visit'] = dfTDb['month']*30 + dfTDb['day']\n",
    "dfTDb = dfTDb.drop(['timestamp','month','day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columna con ultima compra\n",
    "temp = dfE.loc[dfE['event'] == 'conversion'].groupby('person')['timestamp'].max().to_frame()\n",
    "dfTDc = dfTDb.merge(temp, how='left', on='person')\n",
    "dfTDc = dfTDc.fillna('000000000000000000')\n",
    "dfTDc['month'] = dfTDc['timestamp'].str[5:7]\n",
    "dfTDc['day'] = dfTDc['timestamp'].str[8:10]\n",
    "dfTDc[['day','month']] = dfTDc[['day','month']].apply(pd.to_numeric)\n",
    "dfTDc['last_conversion'] = dfTDc['month']*30 + dfTDc['day']\n",
    "dfTDc = dfTDc.drop(['timestamp','month','day'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545760253915411"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_y = dfTDc['label']\n",
    "df_X = dfTDc.drop(['person', 'label'], axis=1)\n",
    "\n",
    "GBC = GradientBoostingClassifier(random_state=23,learning_rate=0.06,subsample=0.75, min_samples_split=8)\n",
    "scores = cross_val_score(GBC , df_X, df_y, scoring=\"roc_auc\", cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrego nuevos features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizo las fechas y los horarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego columnas para separar los meses y la hora\n",
    "datos = dfE.loc[:,['timestamp', 'event', 'person']]\n",
    "datos['date_time'] = pd.to_datetime(datos['timestamp'], format='%Y%m%d %H:%M:%S.%f')\n",
    "datos['mes'] = datos['date_time'].dt.month\n",
    "datos['hora'] = datos['date_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columnas para ver el momento del dia en el que se generaron las conversiones\n",
    "features = datos.loc[ datos['event'] == 'conversion', ['person', 'hora']]\n",
    "features['comp_mañana'] = features['hora'].apply(lambda x: 1 if ((x >= 6) & (x < 12)) else 0)\n",
    "features['comp_tarde'] = features['hora'].apply(lambda x: 1 if ((x >= 12) & (x <20)) else 0)\n",
    "features['comp_noche'] = features['hora'].apply(lambda x: 1 if ((x >= 20) & (x <= 23)) else 0)\n",
    "features['comp_madrugada'] = features['hora'].apply(lambda x: 1 if ((x >= 0) & (x < 6)) else 0)\n",
    "features = features.drop('hora', axis = 'columns').groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago un join con los features anteriores\n",
    "df_feat = pd.merge(dfTDc, features, on = 'person', how = 'left').fillna(0)\n",
    "# Agrego la cantidad de eventos que generaron las personas\n",
    "df_feat['total_events'] = (np.sum(df_feat.iloc[:,2:13], axis = 'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_feat['label']\n",
    "X = df_feat.drop(['person', 'label'], axis = 'columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB1 = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.05,\n",
    "                max_depth = 5, gamma = 4, n_estimators = 100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizo las predicciones y luego calculo el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426087259548369"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = XGB1.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537345254558832"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGB1 , X, y, scoring = \"roc_auc\", cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego más features sobre marcas y modelos de los productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se tienen muchos modelos diferentes pero corresponden a una cantidad acotada de marcas, trabajo sobre las marcas para crear nuevos features. Creo una columna por cada marca existente y para cada persona coloco el promedio de compra para esa marca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo columnas para las marcas existentes\n",
    "compras_por_marcas = dfE.loc[datos['event'] == 'conversion', ['model', 'person']]\n",
    "compras_por_marcas['Samsung_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('samsung' in x.lower()) else 0)\n",
    "compras_por_marcas['iPhone_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('iphone' in x.lower()) else 0)\n",
    "compras_por_marcas['Motorola_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('moto' in x.lower()) else 0)\n",
    "compras_por_marcas['Lenovo_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('lenovo' in x.lower()) else 0)\n",
    "compras_por_marcas['LG_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('lg' in x.lower()) else 0)\n",
    "compras_por_marcas['Sony_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('sony' in x.lower()) else 0)\n",
    "compras_por_marcas['Asus_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('asus' in x.lower()) else 0)\n",
    "compras_por_marcas['iPad_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('iPad' in x.lower()) else 0)\n",
    "compras_por_marcas['Quantum_mean'] = compras_por_marcas['model'].apply(lambda x: 1 if ('quantum' in x.lower()) else 0)\n",
    "new_features = compras_por_marcas.groupby('person').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago join con los features anteriores \n",
    "new_features = pd.merge(df_feat, new_features, on = 'person', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vuelvo a correr XGBoost para ver si con los nuevos features mejoran las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_features['label']\n",
    "X = new_features.drop(['person', 'label'], axis = 'columns')\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2 = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, gamma = 5, n_estimators = 100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo las predicciones y los score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8707324872097599"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = XGB2.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519079473712315"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(XGB2 , X, y, scoring = \"roc_auc\", cv = 10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
